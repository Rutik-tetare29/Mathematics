{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84346db",
   "metadata": {},
   "source": [
    "# Linear Algebra Concepts for Data Science\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6931ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: [5 7 9]\n",
      "Scalar Multiplication: [3 6 9]\n",
      "Dot Product: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define vectors\n",
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([4, 5, 6])\n",
    "\n",
    "# Vector operations\n",
    "add = v1 + v2\n",
    "scalar_mul = 3 * v1\n",
    "dot_product = np.dot(v1, v2)\n",
    "\n",
    "print(\"Addition:\", add)\n",
    "print(\"Scalar Multiplication:\", scalar_mul)\n",
    "print(\"Dot Product:\", dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d1706",
   "metadata": {},
   "source": [
    "## 2. Matrices\n",
    "Matrices are used to represent data transformations, relationships, and computations in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3b8599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      " [[3 2]\n",
      " [4 7]]\n",
      "Multiplication:\n",
      " [[ 4  6]\n",
      " [10 12]]\n",
      "Transpose:\n",
      " [[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "# Define matrices\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[2, 0], [1, 3]])\n",
    "\n",
    "# Matrix operations\n",
    "add = A + B\n",
    "mul = np.dot(A, B)\n",
    "transpose = A.T\n",
    "\n",
    "print(\"Addition:\\n\", add)\n",
    "print(\"Multiplication:\\n\", mul)\n",
    "print(\"Transpose:\\n\", transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4b568",
   "metadata": {},
   "source": [
    "## 3. Systems of Linear Equations\n",
    "Linear equations are often solved to find optimal solutions in regression and other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Solve 2x + y = 5, x - y = 1\n",
    "A = np.array([[2, 1], [1, -1]])\n",
    "b = np.array([5, 1])\n",
    "\n",
    "solution = np.linalg.solve(A, b)\n",
    "print(\"Solution:\", solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec235a",
   "metadata": {},
   "source": [
    "## 4. Eigenvalues and Eigenvectors\n",
    "Eigenvalues and eigenvectors describe matrix transformations and are used in PCA and other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ee03d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [5. 2.]\n",
      "Eigenvectors:\n",
      " [[ 0.89442719 -0.70710678]\n",
      " [ 0.4472136   0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Eigenvalues and eigenvectors\n",
    "A = np.array([[4, 2], [1, 3]])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d2fea",
   "metadata": {},
   "source": [
    "## 5. Norms and Distance Metrics\n",
    "Norms measure vector magnitude, and distance metrics help compute similarity or dissimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1ccd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Norm: 5.0\n",
      "L1 Norm: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Vector norms\n",
    "v = np.array([3, 4])\n",
    "\n",
    "l2_norm = np.linalg.norm(v)  # Euclidean norm\n",
    "l1_norm = np.linalg.norm(v, ord=1)  # Manhattan norm\n",
    "\n",
    "print(\"L2 Norm:\", l2_norm)\n",
    "print(\"L1 Norm:\", l1_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159abc91",
   "metadata": {},
   "source": [
    "## 6. Projections\n",
    "Projections map one vector onto another or onto a subspace, used in dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e2248c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection: [2.2 4.4]\n"
     ]
    }
   ],
   "source": [
    "# Projection of v onto u\n",
    "v = np.array([3, 4])\n",
    "u = np.array([1, 2])\n",
    "\n",
    "projection = (np.dot(v, u) / np.dot(u, u)) * u\n",
    "print(\"Projection:\", projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab766928",
   "metadata": {},
   "source": [
    "## 7. Linear Transformations\n",
    "Linear transformations include scaling, rotation, and translation, represented as matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08192dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Vector: [2 2]\n"
     ]
    }
   ],
   "source": [
    "# Scaling and rotation\n",
    "matrix = np.array([[2, 0], [0, 2]])  # Scaling\n",
    "vector = np.array([1, 1])\n",
    "\n",
    "transformed = np.dot(matrix, vector)\n",
    "print(\"Transformed Vector:\", transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19475147",
   "metadata": {},
   "source": [
    "## 8. Singular Value Decomposition (SVD)\n",
    "SVD decomposes a matrix into three matrices (U, Î£, V^T), used in PCA, latent analysis, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b324370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      " [[-0.2298477   0.88346102  0.40824829]\n",
      " [-0.52474482  0.24078249 -0.81649658]\n",
      " [-0.81964194 -0.40189603  0.40824829]]\n",
      "Singular Values: [9.52551809 0.51430058]\n",
      "V^T:\n",
      " [[-0.61962948 -0.78489445]\n",
      " [-0.78489445  0.61962948]]\n"
     ]
    }
   ],
   "source": [
    "# SVD\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "U, S, Vt = np.linalg.svd(A)\n",
    "\n",
    "print(\"U:\\n\", U)\n",
    "print(\"Singular Values:\", S)\n",
    "print(\"V^T:\\n\", Vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f406f78",
   "metadata": {},
   "source": [
    "## 9. Basis and Dimension\n",
    "A basis is a set of vectors that span a vector space. Dimension is the number of basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3972faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n"
     ]
    }
   ],
   "source": [
    "# Basis and dimension\n",
    "basis = np.array([[1, 0], [0, 1]])  # Standard basis\n",
    "rank = np.linalg.matrix_rank(basis)\n",
    "\n",
    "print(\"Rank:\", rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4efa4d6",
   "metadata": {},
   "source": [
    "## 10. Rank and Determinants\n",
    "Rank determines the number of independent rows or columns in a matrix. Determinants indicate invertibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a87c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Determinant: -2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Rank and determinant\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "rank = np.linalg.matrix_rank(A)\n",
    "determinant = np.linalg.det(A)\n",
    "\n",
    "print(\"Rank:\", rank)\n",
    "print(\"Determinant:\", determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e57a2f",
   "metadata": {},
   "source": [
    "## 11. Orthogonality and Orthogonalization\n",
    "Orthogonality ensures vectors are perpendicular, reducing redundancy in data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6b84dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonal: True\n"
     ]
    }
   ],
   "source": [
    "# Check orthogonality\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0, 1])\n",
    "\n",
    "dot_product = np.dot(v1, v2)\n",
    "print(\"Orthogonal:\", dot_product == 0)  # True if 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb36ac8",
   "metadata": {},
   "source": [
    "## 12. Principal Component Analysis (PCA)\n",
    "PCA reduces data dimensions by projecting data onto principal components with the most variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966ed0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Data:\n",
      " [[ 0.75001714]\n",
      " [-1.85685726]\n",
      " [ 0.91187236]\n",
      " [ 0.19496777]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Example dataset\n",
    "data = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2]])\n",
    "\n",
    "# PCA with 1 component\n",
    "pca = PCA(n_components=1)\n",
    "reduced_data = pca.fit_transform(data)\n",
    "\n",
    "print(\"Reduced Data:\\n\", reduced_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
